import { Topic } from '../syllabus';

export const operatingSystemsUnit3: Topic[] = [
  // Memory Management Strategies
  {
    id: 'memory-management-background',
    name: 'Memory Management Strategies: Background',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Memory management is responsible for managing the computer\'s primary memory, ensuring efficient allocation and protection of memory space.',
      definition: 'The process of controlling and coordinating computer memory, assigning portions to various running programs to optimize overall system performance.',
      realWorldExample: 'Like organizing books in a library - you need to track which shelves are occupied, ensure books don\'t get mixed up, and efficiently use available space.',
      realWorldUse: 'Used in all computing systems to manage RAM allocation, enable multitasking, provide memory protection, and implement virtual memory systems.',
      importance: 'Effective memory management is crucial for system stability, performance, security, and enabling multiple programs to run simultaneously.',
      detailedExplanation: `
## Memory Management Goals:

**Allocation:**
- Assign memory blocks to processes efficiently
- Minimize fragmentation and waste
- Support dynamic memory requests

**Protection:**
- Prevent processes from accessing unauthorized memory
- Isolate process address spaces
- Maintain system security and stability

**Sharing:**
- Enable controlled sharing of memory between processes
- Support shared libraries and inter-process communication
- Optimize memory usage through code sharing

**Virtual Memory:**
- Provide illusion of unlimited memory
- Enable programs larger than physical memory
- Support demand paging and swapping

## Memory Hierarchy:

**Registers:**
- Fastest access (< 1 cycle)
- Smallest capacity (bytes)
- CPU internal storage
- Managed by compiler/processor

**Cache Memory:**
- Very fast access (1-10 cycles)
- Small capacity (KB to MB)
- Hardware managed
- Multiple levels (L1, L2, L3)

**Main Memory (RAM):**
- Fast access (100+ cycles)
- Moderate capacity (GB)
- OS managed
- Volatile storage

**Secondary Storage:**
- Slow access (millions of cycles)
- Large capacity (TB)
- File system managed
- Non-volatile storage

## Address Binding:

**Compile Time:**
- Absolute addresses generated at compile time
- Program must be loaded at specific memory location
- Rarely used in modern systems

**Load Time:**
- Relocatable addresses resolved when program loaded
- Loader adjusts addresses based on actual load location
- More flexible than compile-time binding

**Execution Time:**
- Addresses resolved during program execution
- Enables dynamic relocation of programs
- Requires hardware support (MMU)
- Most common in modern systems

## Logical vs Physical Addresses:

**Logical Address:**
- Generated by CPU during program execution
- Also called virtual address
- Address space starts from 0
- Translated to physical address by MMU

**Physical Address:**
- Actual location in main memory
- Hardware uses this for memory access
- May be different from logical address
- Managed by memory management unit

## Memory Management Unit (MMU):

**Address Translation:**
- Converts logical addresses to physical addresses
- Hardware component for efficiency
- Supports various translation schemes
- Enables virtual memory implementation

**Protection:**
- Checks memory access permissions
- Prevents unauthorized access
- Generates protection violations
- Supports different privilege levels

**Caching:**
- Translation Lookaside Buffer (TLB)
- Caches recent address translations
- Improves translation performance
- Reduces memory access overhead
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=qdkxXygc3rE',
        'https://www.youtube.com/watch?v=7J0JDovnxWA'
      ],
      externalLinks: [
        { title: 'Memory Management in Operating Systems', url: 'https://www.geeksforgeeks.org/memory-management-in-operating-system/' },
        { title: 'Memory Hierarchy', url: 'https://www.tutorialspoint.com/operating_system/os_memory_management.htm' }
      ]
    }
  },
  {
    id: 'swapping',
    name: 'Swapping',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Swapping is a memory management technique where processes are temporarily moved between main memory and secondary storage.',
      definition: 'The process of moving entire processes or parts of processes between main memory (RAM) and secondary storage (disk) to manage memory allocation.',
      realWorldExample: 'Like moving boxes between your workspace and storage room - when you need space for new work, you temporarily store some boxes and bring them back when needed.',
      realWorldUse: 'Used in operating systems to handle memory shortage, support multiprogramming with limited RAM, and manage process scheduling.',
      importance: 'Swapping enables systems to run more processes than can fit in physical memory, improving system utilization and multitasking capabilities.',
      detailedExplanation: `
## Types of Swapping:

**Process Swapping:**
- Entire process moved to/from disk
- Process becomes inactive during swap-out
- Simple but high overhead
- Used in older systems

**Page Swapping:**
- Individual pages moved to/from disk
- Process remains partially active
- More efficient than process swapping
- Used in modern virtual memory systems

## Swapping Operations:

**Swap Out:**
- Move process from main memory to disk
- Free up memory space for other processes
- Process state saved to swap space
- Process marked as swapped out

**Swap In:**
- Move process from disk to main memory
- Allocate memory space for process
- Restore process state from swap space
- Process becomes ready for execution

## Swap Space Management:

**Swap Space Allocation:**
- Dedicated disk partition or file
- Contiguous allocation for efficiency
- Size typically 1-2 times RAM size
- Fast access required

**Swap Space Organization:**
\`\`\`
Swap Space Layout:
|Header|Process 1|Process 2|....|Free Space|

Header contains:
- Swap space size
- Free space bitmap
- Process location table
\`\`\`

## Swapping Algorithms:

**Swap Out Selection:**
- **Longest Idle**: Swap out process idle longest
- **Largest Process**: Free maximum memory
- **Priority Based**: Consider process priority
- **Round Robin**: Fair selection among processes

**Swap In Selection:**
- **Highest Priority**: Bring in most important process
- **Shortest Job**: Minimize swap overhead
- **FIFO**: First swapped out, first swapped in
- **Working Set**: Based on memory requirements

## Performance Considerations:

**Swap Time Calculation:**
\`\`\`
Total Swap Time = Seek Time + Rotational Latency + Transfer Time

For 1MB process on typical disk:
- Seek Time: 10ms
- Rotational Latency: 5ms  
- Transfer Time: 20ms (at 50MB/s)
- Total: 35ms per swap operation
\`\`\`

**Optimization Techniques:**
- **Compress Swapped Data**: Reduce I/O time
- **Swap Prediction**: Anticipate swap needs
- **Partial Swapping**: Swap only necessary parts
- **Multiple Swap Devices**: Parallel I/O operations

## Modern Swapping:

**Demand Paging:**
- Pages swapped individually
- Only needed pages brought into memory
- More efficient than process swapping
- Transparent to applications

**Copy-on-Write:**
- Share pages until modification
- Reduce unnecessary copying
- Optimize fork() operations
- Save memory and swap space

**Swap Files vs Partitions:**
- **Swap Partition**: Dedicated disk space, faster
- **Swap File**: File in regular filesystem, flexible
- **Multiple Swap Areas**: Load balancing, redundancy

## Thrashing:

**Definition:**
- Excessive swapping activity
- System spends more time swapping than executing
- Performance severely degraded
- System becomes unresponsive

**Causes:**
- Too many active processes
- Insufficient physical memory
- Poor locality of reference
- Inadequate swap space

**Prevention:**
- **Working Set Model**: Keep frequently used pages
- **Page Fault Frequency**: Monitor and control
- **Load Control**: Limit number of active processes
- **Memory Allocation**: Ensure adequate memory per process

## Swapping in Different Systems:

**Linux:**
- Uses swap partitions and files
- Supports multiple swap areas
- Priority-based swap selection
- Compressed swap (zswap)

**Windows:**
- Uses page files (pagefile.sys)
- Dynamic page file sizing
- Multiple page files supported
- Virtual memory manager integration

**Mobile Systems:**
- Limited or no swap space
- Aggressive process termination
- Memory compression techniques
- App state preservation
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=6neHp-DpDyk',
        'https://www.youtube.com/watch?v=uvWgrEMBGgU'
      ],
      externalLinks: [
        { title: 'Swapping in Operating Systems', url: 'https://www.geeksforgeeks.org/swapping-in-operating-system/' },
        { title: 'Virtual Memory and Swapping', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'paging',
    name: 'Paging',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Paging is a memory management scheme that eliminates the need for contiguous allocation of physical memory and reduces external fragmentation.',
      definition: 'A memory management technique where physical memory is divided into fixed-size blocks called frames, and logical memory is divided into blocks of the same size called pages.',
      realWorldExample: 'Like organizing a book into numbered pages that can be stored in any available slots in a filing cabinet - pages don\'t need to be stored consecutively.',
      realWorldUse: 'Used in virtually all modern operating systems to implement virtual memory, enable efficient memory allocation, and provide memory protection.',
      importance: 'Paging enables efficient memory utilization, eliminates external fragmentation, and provides the foundation for virtual memory systems.',
      detailedExplanation: `
## Paging Concepts:

**Page:**
- Fixed-size block of logical memory
- Typical sizes: 4KB, 8KB, 16KB
- Numbered from 0 to n-1
- Contains program code or data

**Frame:**
- Fixed-size block of physical memory
- Same size as pages
- Numbered from 0 to m-1
- Available for page allocation

**Page Table:**
- Maps logical pages to physical frames
- One entry per page in logical address space
- Contains frame number and control bits
- Maintained by operating system

## Address Translation:

**Logical Address Structure:**
\`\`\`
|Page Number (p)|Page Offset (d)|
|    n-m bits   |    m bits     |

For 32-bit address with 4KB pages:
- Page offset: 12 bits (2^12 = 4KB)
- Page number: 20 bits (2^20 = 1M pages)
\`\`\`

**Translation Process:**
1. Extract page number (p) and offset (d) from logical address
2. Use page number as index into page table
3. Get frame number (f) from page table entry
4. Physical address = (f × page_size) + d

**Hardware Support:**
- **Page Table Base Register (PTBR)**: Points to page table
- **Page Table Length Register (PTLR)**: Size of page table
- **Translation Lookaside Buffer (TLB)**: Cache for translations

## Page Table Structure:

**Simple Page Table:**
\`\`\`
Page Table Entry:
|Valid|Protection|Reference|Modify|Frame Number|
|  1  |    3     |    1    |  1   |     20     |

- Valid bit: Page is in memory
- Protection: Read/Write/Execute permissions
- Reference: Page has been accessed
- Modify: Page has been modified
- Frame number: Physical frame location
\`\`\`

**Multi-level Page Tables:**
- Reduce page table size for sparse address spaces
- Two-level, three-level, or four-level structures
- Only allocate page table entries as needed

**Example - Two-level Paging:**
\`\`\`
Logical Address:
|P1 (10 bits)|P2 (10 bits)|Offset (12 bits)|

Translation:
1. Use P1 to index outer page table
2. Get address of inner page table
3. Use P2 to index inner page table
4. Get frame number
5. Combine with offset for physical address
\`\`\`

## TLB (Translation Lookaside Buffer):

**Purpose:**
- Cache recent page table entries
- Reduce memory access overhead
- Improve address translation speed

**TLB Hit:**
- Translation found in TLB
- Fast address translation (1 cycle)
- No memory access needed

**TLB Miss:**
- Translation not in TLB
- Access page table in memory
- Update TLB with new entry
- Higher latency (100+ cycles)

**TLB Management:**
- **Hardware-managed**: CPU handles TLB updates
- **Software-managed**: OS handles TLB updates
- **Replacement policies**: LRU, FIFO, Random

## Memory Protection:

**Protection Bits:**
- **Read**: Allow read access
- **Write**: Allow write access  
- **Execute**: Allow instruction execution
- **User/Supervisor**: Privilege level required

**Protection Violation:**
- Hardware detects invalid access
- Generates protection fault
- OS handles violation (typically terminate process)

## Shared Pages:

**Code Sharing:**
- Multiple processes share same code pages
- Read-only pages can be safely shared
- Reduces memory usage
- Common for system libraries

**Implementation:**
- Multiple page tables point to same frames
- Reference counting for shared frames
- Copy-on-write for data sharing

## Advantages and Disadvantages:

**Advantages:**
- Eliminates external fragmentation
- Enables non-contiguous allocation
- Supports virtual memory
- Provides memory protection
- Enables code sharing

**Disadvantages:**
- Internal fragmentation (last page)
- Memory overhead for page tables
- Address translation overhead
- TLB miss penalties
- Complex hardware requirements

## Performance Optimization:

**Large Pages:**
- Reduce TLB misses
- Lower page table overhead
- Better for large applications
- Examples: 2MB, 1GB pages

**Page Coloring:**
- Reduce cache conflicts
- Map pages to specific cache sets
- Improve cache performance
- Important for high-performance systems

**Prefetching:**
- Anticipate page accesses
- Reduce page fault penalties
- Hardware or software implementation
- Effective for sequential access patterns
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=LKe7xK0bF7o',
        'https://www.youtube.com/watch?v=6c-mOFZwP_8'
      ],
      externalLinks: [
        { title: 'Paging in Operating Systems', url: 'https://www.geeksforgeeks.org/paging-in-operating-system/' },
        { title: 'Page Table Structure', url: 'https://www.tutorialspoint.com/operating_system/os_paging.htm' }
      ]
    }
  },
  {
    id: 'virtual-memory-management',
    name: 'Virtual Memory Management',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Virtual memory is a memory management technique that provides an idealized abstraction of storage resources, giving programs the illusion of unlimited memory.',
      definition: 'A memory management technique that uses hardware and software to allow a computer to compensate for physical memory shortages by temporarily transferring data to disk storage.',
      realWorldExample: 'Like having a small desk but a large filing cabinet - you keep currently needed documents on the desk and store others in the cabinet, bringing them to the desk when needed.',
      realWorldUse: 'Used in all modern operating systems to enable running programs larger than physical memory, support multiprogramming, and provide memory isolation.',
      importance: 'Virtual memory enables efficient memory utilization, supports large applications, provides memory protection, and allows more programs to run simultaneously.',
      detailedExplanation: `
## Virtual Memory Concepts:

**Virtual Address Space:**
- Logical view of memory as seen by process
- Can be larger than physical memory
- Provides uniform memory model
- Enables memory protection and sharing

**Demand Paging:**
- Pages loaded into memory only when needed
- Reduces memory usage and startup time
- Enables programs larger than physical memory
- Transparent to applications

**Page Fault:**
- Hardware interrupt when accessing non-resident page
- OS handles by loading page from storage
- Process blocked until page available
- Transparent to application

## Demand Paging Implementation:

**Page Fault Handling:**
\`\`\`
1. Hardware detects page not in memory
2. Generate page fault interrupt
3. OS determines fault cause:
   - Invalid address → Terminate process
   - Valid but not loaded → Load page
4. Find free frame or select victim
5. Load page from storage to frame
6. Update page table
7. Restart interrupted instruction
\`\`\`

**Lazy Loading:**
- Load pages only when accessed
- Reduces program startup time
- Saves memory for unused code/data
- Common in modern systems

**Copy-on-Write (COW):**
- Share pages until modification
- Create copy only when written
- Optimizes fork() operation
- Reduces memory usage

## Page Replacement Algorithms:

**FIFO (First-In-First-Out):**
\`\`\`
Reference String: 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1
Frames: 3

Page Faults with FIFO:
Frame 1: 7 7 7 2 2 2 4 4 4 0 0 0 0 0 0 1 1 1 1 1
Frame 2: - 0 0 0 0 3 3 3 2 2 2 3 3 3 2 2 2 7 7 7  
Frame 3: - - 1 1 1 1 0 0 0 3 3 3 2 1 1 1 0 0 0 0

Page Faults: 15
\`\`\`

**LRU (Least Recently Used):**
- Replace page not used for longest time
- Optimal for programs with locality
- Implementation: Stack, counter, or approximation
- Better performance than FIFO

**Optimal Algorithm:**
- Replace page that will be used farthest in future
- Theoretical optimal (requires future knowledge)
- Used as benchmark for other algorithms
- Not implementable in practice

**Clock Algorithm:**
- Approximation of LRU using reference bit
- Circular list of pages with pointer
- Clear reference bit and advance on each sweep
- Replace page with reference bit = 0

## Thrashing:

**Definition:**
- System spends more time paging than executing
- Caused by insufficient memory for working sets
- Severe performance degradation
- System becomes unresponsive

**Working Set Model:**
- Set of pages referenced in recent time window
- Locality principle: programs reference small subset
- Working set size varies over time
- System should maintain working sets in memory

**Page Fault Frequency (PFF):**
- Monitor page fault rate per process
- Increase allocation if PFF too high
- Decrease allocation if PFF too low
- Dynamic adjustment based on behavior

## Memory-Mapped Files:

**Concept:**
- Map file contents to virtual memory
- File I/O through memory operations
- Lazy loading of file contents
- Automatic synchronization

**Advantages:**
- Simplified file I/O programming
- Efficient for large files
- Shared memory between processes
- Automatic caching by OS

**Implementation:**
\`\`\`c
// Memory map a file
void *addr = mmap(NULL, file_size, PROT_READ|PROT_WRITE, 
                  MAP_SHARED, fd, 0);

// Access file through memory
char *data = (char *)addr;
data[100] = 'A';  // Modify file content

// Unmap when done
munmap(addr, file_size);
\`\`\`

## Kernel Memory Allocation:

**Buddy System:**
- Allocate memory in powers of 2
- Split and coalesce blocks efficiently
- Reduces external fragmentation
- Used in Linux kernel

**Slab Allocator:**
- Pre-allocate objects of specific sizes
- Reduces allocation/deallocation overhead
- Improves cache performance
- Used for kernel data structures

**SLUB Allocator:**
- Simplified slab allocator
- Better performance and less memory overhead
- Default in modern Linux kernels
- Improved debugging capabilities

## Virtual Memory Benefits:

**Memory Isolation:**
- Each process has separate address space
- Protection from other processes
- Security and stability improvements
- Simplified programming model

**Memory Sharing:**
- Controlled sharing between processes
- Shared libraries and code segments
- Inter-process communication
- Reduced memory usage

**Memory Overcommitment:**
- Allocate more virtual memory than physical
- Rely on not all memory being used
- Improve system utilization
- Risk of out-of-memory conditions

## Performance Considerations:

**TLB Management:**
- Keep frequently used translations in TLB
- Minimize TLB misses
- Use large pages when appropriate
- Consider TLB size in algorithm design

**Page Size Selection:**
- Larger pages: Fewer TLB misses, more internal fragmentation
- Smaller pages: Less fragmentation, more TLB misses
- Multiple page sizes: Best of both worlds
- Application-specific optimization

**Locality Optimization:**
- Spatial locality: Access nearby memory locations
- Temporal locality: Reuse recently accessed data
- Algorithm design should consider locality
- Data structure layout optimization
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=qcBIvnQt0Bw',
        'https://www.youtube.com/watch?v=uvWgrEMBGgU'
      ],
      externalLinks: [
        { title: 'Virtual Memory in Operating Systems', url: 'https://www.geeksforgeeks.org/virtual-memory-in-operating-system/' },
        { title: 'Page Replacement Algorithms', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'contiguous-memory-allocation',
    name: 'Contiguous Memory Allocation',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Contiguous memory allocation assigns consecutive memory locations to processes, providing simple and efficient memory management for early operating systems.',
      definition: 'A memory allocation scheme where each process is allocated a single contiguous block of memory locations in the main memory.',
      realWorldExample: 'Like assigning consecutive seats in a theater to a group, where all members sit together in adjacent seats without gaps.',
      realWorldUse: 'Used in embedded systems, real-time systems, and simple operating systems where memory management overhead must be minimized.',
      importance: 'Forms the foundation for understanding memory management concepts and is still used in systems requiring predictable memory access patterns.',
      detailedExplanation: `
Fixed Partitioning divides memory into fixed-size partitions where each partition can hold one process. This approach is simple but suffers from internal fragmentation when processes are smaller than partitions and external fragmentation when no partition is large enough for a process.

Variable Partitioning allocates exactly the amount of memory needed by each process, eliminating internal fragmentation. However, this approach creates external fragmentation as processes terminate and leave gaps that may be too small for new processes.

Memory Allocation Algorithms include First Fit which allocates the first available block large enough for the process, Best Fit which finds the smallest block that can accommodate the process, and Worst Fit which allocates the largest available block.

Compaction addresses external fragmentation by moving all allocated partitions to one end of memory, combining all free space into one large block. This process requires updating all memory references and can be time-consuming.

Protection Mechanisms ensure processes cannot access memory outside their allocated regions using base and limit registers. The base register contains the starting address while the limit register contains the size of the allocated region.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=p9yZNLeOj4s',
        'https://www.youtube.com/watch?v=1VDP5TCAK2c'
      ],
      externalLinks: [
        { title: 'Contiguous Memory Allocation', url: 'https://www.geeksforgeeks.org/fixed-dynamic-partitioning-operating-system/' },
        { title: 'Memory Management Techniques', url: 'https://www.tutorialspoint.com/operating_system/os_memory_management.htm' }
      ]
    }
  },
  {
    id: 'segmentation',
    name: 'Segmentation',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Segmentation divides the logical address space into variable-sized segments that correspond to logical divisions of a program such as functions, data structures, and arrays.',
      definition: 'A memory management technique that divides the logical address space into segments of varying sizes, each representing a logical unit of the program.',
      realWorldExample: 'Like organizing a library where books are grouped by subject (fiction, science, history) with each section having different sizes based on the number of books.',
      realWorldUse: 'Used in systems requiring logical separation of program components, protection mechanisms, and sharing of code segments between processes.',
      importance: 'Provides logical organization of memory that matches program structure, enabling better protection and sharing mechanisms compared to simple paging.',
      detailedExplanation: `
Segment Structure consists of a segment number and offset within the segment. The logical address is divided into these two parts, where the segment number indexes into a segment table to find the base address and limit of the segment.

Segment Table contains entries for each segment with base address pointing to the physical memory location where the segment begins and limit specifying the segment size. The hardware uses this information for address translation and protection.

Address Translation involves using the segment number to index the segment table, checking if the offset is within the segment limit, and adding the offset to the base address to obtain the physical address. Invalid accesses generate segmentation faults.

Protection and Sharing mechanisms allow different segments to have different access permissions (read, write, execute) and enable sharing of code segments between processes while maintaining separate data segments for each process.

Segmentation Problems include external fragmentation as segments of varying sizes create gaps in memory, and the need for complex memory management algorithms to handle allocation and deallocation of variable-sized segments.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=p9yZNLeOj4s',
        'https://www.youtube.com/watch?v=dz9Tk6KCMlQ'
      ],
      externalLinks: [
        { title: 'Segmentation in Operating System', url: 'https://www.geeksforgeeks.org/segmentation-in-operating-system/' },
        { title: 'Memory Segmentation', url: 'https://www.tutorialspoint.com/operating_system/os_memory_segmentation.htm' }
      ]
    }
  },
  {
    id: 'page-table-structure',
    name: 'Structure of the Page Table',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'The page table structure defines how virtual-to-physical address mappings are organized and accessed, affecting both memory usage and translation performance.',
      definition: 'The organization and format of page tables that store the mapping between virtual page numbers and physical frame numbers in a paging system.',
      realWorldExample: 'Like a phone directory organized in different ways - a simple list, hierarchical sections by area code, or a hash table for quick lookup.',
      realWorldUse: 'Used in all modern operating systems with virtual memory, including Linux, Windows, and mobile operating systems for efficient address translation.',
      importance: 'Page table structure directly impacts memory overhead, translation speed, and scalability of virtual memory systems in modern computers.',
      detailedExplanation: `
Single Level Page Tables store all page table entries in one contiguous table indexed by virtual page number. This approach is simple but requires large amounts of memory for processes with large address spaces, making it impractical for modern systems.

Hierarchical Page Tables use multiple levels of page tables to reduce memory overhead. Two-level page tables divide the virtual address into page directory index, page table index, and offset, allowing sparse address spaces to use less memory.

Hashed Page Tables use hash functions to map virtual page numbers to page table entries, providing constant-time lookup for sparse address spaces. Collision handling uses chaining or open addressing to resolve hash conflicts.

Inverted Page Tables maintain one entry per physical frame rather than per virtual page, significantly reducing memory overhead. Each entry contains the virtual page number and process ID that owns the frame, requiring hash tables for efficient lookup.

Translation Lookaside Buffer (TLB) caches recent page table entries to avoid memory accesses for address translation. TLB structure includes virtual page number, physical frame number, and protection bits with replacement policies for cache management.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=qcBIvnQt0Bw',
        'https://www.youtube.com/watch?v=6neHHkI0Z0o'
      ],
      externalLinks: [
        { title: 'Page Table Structure', url: 'https://www.geeksforgeeks.org/page-table-entries-in-page-table/' },
        { title: 'Multilevel Paging', url: 'https://www.tutorialspoint.com/operating_system/os_paging.htm' }
      ]
    }
  },
  {
    id: 'demand-paging',
    name: 'Demand Paging',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Demand paging loads pages into memory only when they are accessed, allowing programs larger than physical memory to execute efficiently.',
      definition: 'A virtual memory management technique where pages are loaded into physical memory only when they are referenced by the running program.',
      realWorldExample: 'Like a library that brings books from storage to reading rooms only when someone requests them, rather than keeping all books available at all times.',
      realWorldUse: 'Used in all modern operating systems to enable efficient memory utilization and support for programs larger than available physical memory.',
      importance: 'Enables efficient memory usage, faster program startup times, and the ability to run more programs simultaneously than physical memory would normally allow.',
      detailedExplanation: `
Page Fault Handling occurs when a process accesses a page not currently in memory. The hardware generates a page fault interrupt, the operating system selects a victim page if memory is full, writes the victim to storage if modified, loads the requested page, and updates page tables.

Lazy Loading defers loading pages until they are actually needed, reducing program startup time and memory usage. Many pages may never be accessed during program execution, making this approach highly efficient for typical program behavior.

Valid-Invalid Bits in page table entries indicate whether a page is currently in memory. Invalid bits trigger page faults when accessed, allowing the operating system to load the page on demand and update the page table entry.

Performance Optimization techniques include prefetching likely-to-be-used pages, clustering page I/O operations, and using efficient page replacement algorithms. The goal is to minimize page fault frequency and I/O overhead.

Working Set Management tracks the set of pages actively used by a process to make informed decisions about which pages to keep in memory and which to swap out, improving overall system performance.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=uvWgrEMBGgU',
        'https://www.youtube.com/watch?v=qcBIvnQt0Bw'
      ],
      externalLinks: [
        { title: 'Demand Paging', url: 'https://www.geeksforgeeks.org/virtual-memory-in-operating-system/' },
        { title: 'Page Fault Handling', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'copy-on-write',
    name: 'Copy-on-Write',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Copy-on-Write is an optimization technique that delays copying of pages until one of the sharing processes attempts to modify the shared page.',
      definition: 'A memory management optimization where multiple processes share the same physical pages until one process writes to a page, at which point a private copy is created.',
      realWorldExample: 'Like sharing a document where everyone reads the same copy until someone wants to make changes, then they get their own personal copy to modify.',
      realWorldUse: 'Used in process creation (fork system call), virtual memory systems, and file systems to reduce memory usage and improve performance.',
      importance: 'Significantly reduces memory usage and improves performance in scenarios involving process creation and memory sharing between related processes.',
      detailedExplanation: `
Fork Implementation uses copy-on-write to make process creation efficient. When a process forks, both parent and child initially share the same physical pages marked as read-only. When either process writes to a page, a page fault occurs and a private copy is created.

Page Protection Mechanisms mark shared pages as read-only in page table entries. Write attempts generate protection faults that trigger the copy-on-write mechanism, creating private copies and updating page table entries to allow writing.

Memory Savings can be substantial when processes share large amounts of data or when child processes exec new programs shortly after forking. Many pages may never be written, avoiding unnecessary copying and memory allocation.

Implementation Details involve reference counting for shared pages, efficient page copying mechanisms, and careful handling of page table updates. The system must ensure atomicity of copy-on-write operations to maintain consistency.

Performance Benefits include faster process creation, reduced memory pressure, and improved cache locality. However, the technique adds complexity to memory management and may cause delays when writes actually occur.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=uvWgrEMBGgU',
        'https://www.youtube.com/watch?v=MaqarTIGFxU'
      ],
      externalLinks: [
        { title: 'Copy on Write', url: 'https://www.geeksforgeeks.org/copy-on-write/' },
        { title: 'COW in Operating Systems', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'page-replacement',
    name: 'Page Replacement',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Page replacement algorithms determine which page to remove from memory when a new page must be loaded but physical memory is full.',
      definition: 'Algorithms used to select victim pages for removal from physical memory when space is needed for new pages in demand paging systems.',
      realWorldExample: 'Like deciding which books to return to storage when a library reading room is full and new books are requested - you might remove the oldest, least recently used, or least likely to be needed again.',
      realWorldUse: 'Used in all virtual memory systems to manage limited physical memory efficiently and minimize page fault rates.',
      importance: 'Critical for virtual memory performance as poor page replacement decisions can lead to thrashing and severe performance degradation.',
      detailedExplanation: `
FIFO (First-In-First-Out) Algorithm replaces the page that has been in memory the longest. This simple approach is easy to implement but may remove frequently used pages, leading to poor performance and Belady's anomaly where more frames can result in more page faults.

LRU (Least Recently Used) Algorithm replaces the page that has not been accessed for the longest time, based on the principle of temporal locality. LRU generally performs well but requires expensive hardware support or software approximations to track page access times.

Optimal Algorithm replaces the page that will not be used for the longest time in the future. This theoretical algorithm provides the minimum possible page fault rate but is impossible to implement since future page references are unknown.

Clock Algorithm approximates LRU using a reference bit for each page and a circular list. The algorithm scans pages in circular order, giving pages with reference bits set a second chance before replacement, providing good performance with low overhead.

Enhanced Second Chance Algorithm considers both reference and modify bits to make replacement decisions. Clean pages are preferred over dirty pages for replacement since dirty pages require write-back to storage, adding I/O overhead.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=uvWgrEMBGgU',
        'https://www.youtube.com/watch?v=16kaPQtYo1I'
      ],
      externalLinks: [
        { title: 'Page Replacement Algorithms', url: 'https://www.geeksforgeeks.org/page-replacement-algorithms-in-operating-systems/' },
        { title: 'LRU and FIFO Algorithms', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'allocation-of-frames',
    name: 'Allocation of Frames',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Frame allocation determines how available physical memory frames are distributed among processes in a virtual memory system.',
      definition: 'The process of deciding how many physical memory frames to allocate to each process and which frames to assign when page faults occur.',
      realWorldExample: 'Like distributing parking spaces in a lot among different departments - each department gets a fair share based on their needs and importance.',
      realWorldUse: 'Used in all virtual memory systems to ensure fair memory distribution, prevent thrashing, and optimize overall system performance.',
      importance: 'Proper frame allocation is crucial for system performance, preventing thrashing, and ensuring all processes get adequate memory to function efficiently.',
      detailedExplanation: `
Equal Allocation gives each process the same number of frames regardless of process size or priority. This simple approach ensures fairness but may be inefficient for processes with different memory requirements.

Proportional Allocation distributes frames based on process size, giving larger processes more frames. This approach better matches memory allocation to actual needs but may not consider process behavior or priority.

Priority-based Allocation considers process priority when distributing frames, giving higher priority processes more memory. This approach improves system responsiveness but may starve low-priority processes.

Working Set Allocation attempts to give each process enough frames to hold its working set, the set of pages actively used. This approach minimizes page faults but requires dynamic monitoring of process behavior.

Page Fault Frequency Allocation monitors page fault rates and adjusts frame allocation accordingly. Processes with high page fault rates receive more frames while those with low rates may have frames taken away.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=uvWgrEMBGgU',
        'https://www.youtube.com/watch?v=16kaPQtYo1I'
      ],
      externalLinks: [
        { title: 'Frame Allocation', url: 'https://www.geeksforgeeks.org/allocation-of-frames-in-operating-system/' },
        { title: 'Memory Allocation Strategies', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'thrashing',
    name: 'Thrashing',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Thrashing occurs when a system spends more time swapping pages in and out of memory than executing actual program instructions.',
      definition: 'A condition where excessive paging activity occurs, causing system performance to degrade severely as the system spends most of its time handling page faults.',
      realWorldExample: 'Like a library where staff spend all their time moving books between storage and reading rooms instead of helping patrons, making the library effectively unusable.',
      realWorldUse: 'Understanding thrashing is crucial for system administrators and OS designers to prevent performance degradation in virtual memory systems.',
      importance: 'Preventing thrashing is essential for maintaining system performance and ensuring that virtual memory systems remain beneficial rather than detrimental.',
      detailedExplanation: `
Thrashing Causes include insufficient physical memory for the combined working sets of active processes, poor locality of reference in programs, and excessive multiprogramming where too many processes compete for limited memory.

Working Set Model defines the working set as the collection of pages referenced by a process during a recent time window. Thrashing occurs when the sum of working set sizes exceeds available physical memory.

Page Fault Frequency approach monitors the rate of page faults for each process. When page fault frequency exceeds a threshold, the process needs more frames. When it falls below a threshold, frames can be reclaimed.

Thrashing Prevention strategies include limiting the degree of multiprogramming, ensuring adequate memory allocation per process, using working set algorithms, and implementing load control mechanisms.

Recovery from Thrashing involves suspending some processes to reduce memory pressure, increasing physical memory, or terminating memory-intensive processes to restore system balance.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=uvWgrEMBGgU',
        'https://www.youtube.com/watch?v=Dhf-DsO3d8c'
      ],
      externalLinks: [
        { title: 'Thrashing in Operating System', url: 'https://www.geeksforgeeks.org/thrashing-in-operating-system/' },
        { title: 'Working Set Model', url: 'https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm' }
      ]
    }
  },
  {
    id: 'memory-mapped-files',
    name: 'Memory-Mapped Files',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Memory-mapped files allow file contents to be accessed through memory operations, providing an efficient interface between file I/O and memory management.',
      definition: 'A technique that maps file contents directly into the virtual address space of a process, allowing file access through normal memory read and write operations.',
      realWorldExample: 'Like having a magic window where looking through it shows the contents of a book in another room, and writing on the window changes the book directly.',
      realWorldUse: 'Used in database systems, image processing applications, shared memory implementations, and any application requiring efficient file access.',
      importance: 'Memory-mapped files provide high-performance file I/O, enable easy sharing between processes, and simplify programming by treating files as memory.',
      detailedExplanation: `
Memory Mapping Process involves the operating system creating a mapping between a portion of the virtual address space and a file on disk. The file contents are not immediately loaded but are brought into memory on demand as pages are accessed.

Shared Mappings allow multiple processes to map the same file, enabling efficient inter-process communication and data sharing. Changes made by one process are visible to others, providing a natural shared memory mechanism.

Private Mappings create copy-on-write mappings where each process gets its own copy of modified pages. This allows processes to have private views of files while sharing unmodified portions.

Lazy Loading means file contents are loaded into memory only when accessed, similar to demand paging. This reduces memory usage and improves startup time for applications accessing large files.

Synchronization between memory and file contents can be explicit using msync() system calls or implicit when pages are written back to storage during normal virtual memory operations.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=MaqarTIGFxU',
        'https://www.youtube.com/watch?v=qcBIvnQt0Bw'
      ],
      externalLinks: [
        { title: 'Memory Mapped Files', url: 'https://www.geeksforgeeks.org/memory-mapped-files/' },
        { title: 'File Mapping', url: 'https://www.tutorialspoint.com/operating_system/os_file_system.htm' }
      ]
    }
  },
  {
    id: 'kernel-memory-allocation',
    name: 'Allocating Kernel Memory',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'Kernel memory allocation manages memory for operating system data structures and requires different strategies than user space allocation.',
      definition: 'Specialized memory management techniques used by the operating system kernel to allocate memory for its own data structures and operations.',
      realWorldExample: 'Like a hospital having separate supply rooms for different departments with specialized equipment that requires careful organization and quick access.',
      realWorldUse: 'Used internally by operating systems to manage kernel data structures, device drivers, and system resources efficiently.',
      importance: 'Efficient kernel memory allocation is crucial for system performance, stability, and resource utilization in operating systems.',
      detailedExplanation: `
Buddy System Algorithm allocates memory in blocks whose sizes are powers of two. When a block is needed, larger blocks are split recursively, and when blocks are freed, adjacent buddy blocks are coalesced to reduce fragmentation.

Slab Allocation pre-allocates objects of specific sizes in caches, reducing allocation and deallocation overhead. Each slab contains multiple objects of the same type, improving cache performance and reducing fragmentation.

SLUB Allocator is a simplified version of slab allocation with better performance and lower memory overhead. It reduces complexity while maintaining the benefits of object caching and is used in modern Linux kernels.

Kernel Memory Requirements differ from user space because kernel needs guaranteed allocation, cannot page fault during critical operations, and requires specific alignment and contiguity for hardware interactions.

Memory Pools maintain pre-allocated memory for critical operations that cannot fail, ensuring system stability during low memory conditions and providing predictable allocation performance.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=MaqarTIGFxU',
        'https://www.youtube.com/watch?v=7J0JDovnxWA'
      ],
      externalLinks: [
        { title: 'Kernel Memory Allocation', url: 'https://www.geeksforgeeks.org/buddy-system-memory-allocation-technique/' },
        { title: 'Slab Allocation', url: 'https://www.tutorialspoint.com/operating_system/os_memory_management.htm' }
      ]
    }
  },
  {
    id: 'file-system-concept',
    name: 'File System: File Concept',
    semester: 2,
    subject: 'Operating Systems',
    unit: 'Unit III',
    content: {
      introduction: 'File systems provide a logical organization for storing and retrieving data on storage devices, abstracting the complexity of physical storage.',
      definition: 'A method and data structure that an operating system uses to control how data is stored and retrieved on storage devices.',
      realWorldExample: 'Like a filing cabinet system in an office where documents are organized in folders, labeled, and stored in a structured way for easy retrieval.',
      realWorldUse: 'Used in all computing systems to organize data storage, from personal computers to servers and mobile devices.',
      importance: 'File systems are fundamental to data organization, providing persistent storage, data integrity, and efficient access to information.',
      detailedExplanation: `
File Attributes include name for human identification, type indicating file format, location specifying storage address, size showing current file length, protection defining access permissions, and timestamps recording creation and modification times.

File Types can be regular files containing user data, directories containing file listings, special files representing devices or system resources, and symbolic links pointing to other files or directories.

File Operations include create for making new files, open for preparing file access, read and write for data transfer, seek for positioning within files, close for finishing access, and delete for removing files.

File Structure can be unstructured byte streams, structured records with fixed or variable lengths, or complex formats with headers, metadata, and organized data sections depending on application requirements.

File Naming Conventions vary by system but typically include restrictions on length, allowed characters, case sensitivity, and extension usage to indicate file types and associated applications.
      `,
      youtubeLinks: [
        'https://www.youtube.com/watch?v=KN8YgJnShPM',
        'https://www.youtube.com/watch?v=mzUyMy7Ihk0'
      ],
      externalLinks: [
        { title: 'File System Concepts', url: 'https://www.geeksforgeeks.org/file-systems-in-operating-system/' },
        { title: 'File Operations', url: 'https://www.tutorialspoint.com/operating_system/os_file_system.htm' }
      ]
    }
  }
];